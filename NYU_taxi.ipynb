{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SS9MI0UdO7D",
        "outputId": "cb8942b8-216e-40b8-8cb2-74fc60cbf10b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 57.6 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.43.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.4.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
            "\u001b[K     |████████████████████████████████| 171 kB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (4.10.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray) (1.13.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->redis>=3.5.0->ray) (3.0.6)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.0)\n",
            "Installing collected packages: deprecated, redis, ray\n",
            "Successfully installed deprecated-1.2.13 ray-1.9.2 redis-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M81rx4yLdluh",
        "outputId": "3337c255-e094-41d3-82b7-8f10240d0404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (1.9.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.43.0)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.19.5)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 25.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.10.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->redis>=3.5.0->ray[tune]) (3.0.6)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install \"ray[tune]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_tEiJDxodtU-",
        "outputId": "0b6aa43d-5f12-43db-ab8c-3c7c63330e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting raydp\n",
            "  Downloading raydp-0.4.1-py3-none-any.whl (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 22.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ray[default]>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from raydp) (1.9.2)\n",
            "Requirement already satisfied: pyarrow>=0.10 in /usr/local/lib/python3.7/dist-packages (from raydp) (3.0.0)\n",
            "Collecting netifaces\n",
            "  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from raydp) (5.4.8)\n",
            "Collecting aiohttp==3.7.4\n",
            "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from raydp) (1.19.5)\n",
            "Collecting pyspark>=3.2.0\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 42 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from raydp) (1.1.5)\n",
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 43.8 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->raydp) (21.4.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->raydp) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->raydp) (3.10.0.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->raydp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->raydp) (2.8.2)\n",
            "Collecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->raydp) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (1.43.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (7.1.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (1.0.3)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (4.1.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (3.4.2)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (0.12.0)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 62.4 MB/s \n",
            "\u001b[?25hCollecting aioredis<2\n",
            "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting frozenlist\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 53.8 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 255 kB/s \n",
            "\u001b[?25hCollecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (2.23.0)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 64.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (5.2.1)\n",
            "Collecting hiredis\n",
            "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]>=1.8.0->raydp) (7.352.0)\n",
            "Collecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]>=1.8.0->raydp) (0.2.5)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]>=1.8.0->raydp) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]>=1.8.0->raydp) (4.10.0)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]>=1.8.0->raydp) (1.2.13)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]>=1.8.0->raydp) (1.13.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[default]>=1.8.0->raydp) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->redis>=3.5.0->ray[default]>=1.8.0->raydp) (3.0.6)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.7.4->raydp) (2.10)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]>=1.8.0->raydp) (0.18.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]>=1.8.0->raydp) (5.4.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]>=1.8.0->raydp) (1.26.3)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (1.54.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (4.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]>=1.8.0->raydp) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]>=1.8.0->raydp) (1.24.3)\n",
            "Building wheels for collected packages: pyspark, gpustat, typing\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805911 sha256=bea5b6b2f8f162465f59459d27cc07de04b98b403d0d759fee4a436769ae1a3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=427cff027df2c307b9d1b6dc12fb837e1e8fef66befe0e4779b6a8e458e31f26\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26325 sha256=1c4746564f73bd99be04f296bac08ba1f5e2e0b038bebac968a78b2cad916feb\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\n",
            "Successfully built pyspark gpustat typing\n",
            "Installing collected packages: multidict, yarl, async-timeout, opencensus-context, hiredis, frozenlist, blessed, aiohttp, py4j, py-spy, opencensus, gpustat, colorful, aiosignal, aioredis, aiohttp-cors, typing, pyspark, netifaces, raydp\n",
            "Successfully installed aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 async-timeout-3.0.1 blessed-1.19.0 colorful-0.5.4 frozenlist-1.2.0 gpustat-1.0.0b1 hiredis-2.0.0 multidict-5.2.0 netifaces-0.11.0 opencensus-0.8.0 opencensus-context-0.1.2 py-spy-0.3.11 py4j-0.10.9.2 pyspark-3.2.0 raydp-0.4.1 typing-3.7.4.3 yarl-1.7.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install raydp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFluQUVydvCY",
        "outputId": "3ab8bc3b-0b1d-4edf-8bda-7d89b6d76eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xgboost_ray\n",
            "  Downloading xgboost_ray-0.1.6-py3-none-any.whl (137 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 137 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.1.5)\n",
            "Requirement already satisfied: ray>=1.6 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.9.2)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (0.90)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.19.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (21.4.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (1.0.3)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.13)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (4.1.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (1.43.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.4.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (4.3.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray>=1.6->xgboost_ray) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray>=1.6->xgboost_ray) (4.10.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray>=1.6->xgboost_ray) (21.3)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray>=1.6->xgboost_ray) (1.2.13)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray>=1.6->xgboost_ray) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray>=1.6->xgboost_ray) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->redis>=3.5.0->ray>=1.6->xgboost_ray) (3.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost>=0.90->xgboost_ray) (1.4.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray>=1.6->xgboost_ray) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray>=1.6->xgboost_ray) (0.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->xgboost_ray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->xgboost_ray) (2018.9)\n",
            "Installing collected packages: xgboost-ray\n",
            "Successfully installed xgboost-ray-0.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install \"xgboost_ray\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5J_3ghdB631",
        "outputId": "3edc744d-b49c-45e5-f4e9-4abfa2ba160f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing random_nyctaxi.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile random_nyctaxi.py\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "base_date = np.datetime64('2010-01-01 00:00:00')\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Rabdin NYC taxi Generator')\n",
        "parser.add_argument(\n",
        "    '--num-records',\n",
        "    type=int,\n",
        "    default=2000,\n",
        "    metavar='N',\n",
        "    help='number of records to generate (default: 2000)')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "N = args.num_records\n",
        "\n",
        "fare_amount = np.random.uniform(3.0, 50.0, size=N)\n",
        "pick_long = np.random.uniform(-74.2, -73.8, size=N)\n",
        "pick_lat = np.random.uniform(40.7, 40.8, size=N)\n",
        "drop_long = np.random.uniform(-74.2, -73.8, size=N)\n",
        "drop_lat = np.random.uniform(40.7, 40.8, size=N)\n",
        "passenger_count = np.random.randint(1, 5, size=N)\n",
        "date = np.random.randint(0, 157680000, size=N) + base_date\n",
        "date = np.array([t.item().strftime('%Y-%m-%d %H:%m:%S UTC') for t in date])\n",
        "key = ['fake_key'] * N\n",
        "df = pd.DataFrame({\n",
        "    'key': key,\n",
        "    'fare_amount':fare_amount,\n",
        "    'pickup_datetime': date,\n",
        "    'pickup_longitude': pick_long,\n",
        "    'pickup_latitude': pick_lat,\n",
        "    'dropoff_longitude': drop_long,\n",
        "    'dropoff_latitude': drop_lat,\n",
        "    'passenger_count': passenger_count\n",
        "    })\n",
        "csv_path = os.path.dirname(os.path.realpath(__file__)) + '/fake_nyctaxi.csv'\n",
        "df.to_csv(csv_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ9-zInlCdzL"
      },
      "outputs": [],
      "source": [
        "!python random_nyctaxi.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4mKzjNCBxwh",
        "outputId": "2361b835-259a-45f8-e251-39bba0077ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing data_process.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile data_process.py\n",
        "from os.path import dirname, realpath\n",
        "\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# change this to where the dataset is\n",
        "NYC_TRAIN_CSV = 'file://' + dirname(realpath(__file__)) + '/fake_nyctaxi.csv'\n",
        "\n",
        "def clean_up(data):\n",
        "    data = data.filter(col('pickup_longitude')<=-72) \\\n",
        "            .filter(col('pickup_longitude')>=-76) \\\n",
        "            .filter(col('dropoff_longitude')<=-72) \\\n",
        "            .filter(col('dropoff_longitude')>=-76) \\\n",
        "            .filter(col('pickup_latitude')<=42) \\\n",
        "            .filter(col('pickup_latitude')>=38) \\\n",
        "            .filter(col('dropoff_latitude')<=42) \\\n",
        "            .filter(col('dropoff_latitude')>=38) \\\n",
        "            .filter(col('passenger_count')<=6) \\\n",
        "            .filter(col('passenger_count')>=1) \\\n",
        "            .filter(col('fare_amount') > 0) \\\n",
        "            .filter(col('fare_amount') < 250) \\\n",
        "            .filter(col('dropoff_longitude') != col('pickup_longitude')) \\\n",
        "            .filter(col('dropoff_latitude') != col('pickup_latitude')) \n",
        "    return data\n",
        "\n",
        "# Add time related features\n",
        "def add_time_features(data):\n",
        "    data = data.withColumn(\"day\", dayofmonth(col(\"pickup_datetime\")))\n",
        "    data = data.withColumn(\"hour_of_day\", hour(col(\"pickup_datetime\")))\n",
        "    data = data.withColumn(\"day_of_week\", dayofweek(col(\"pickup_datetime\"))-2)\n",
        "    data = data.withColumn(\"week_of_year\", weekofyear(col(\"pickup_datetime\")))\n",
        "    data = data.withColumn(\"month_of_year\", month(col(\"pickup_datetime\")))\n",
        "    data = data.withColumn(\"quarter_of_year\", quarter(col(\"pickup_datetime\")))\n",
        "    data = data.withColumn(\"year\", year(col(\"pickup_datetime\")))\n",
        "    \n",
        "    @udf(\"int\")\n",
        "    def night(hour, weekday):\n",
        "        if ((hour <= 20) and (hour >= 16) and (weekday < 5)):\n",
        "            return int(1)\n",
        "        else:\n",
        "            return int(0)\n",
        "\n",
        "    @udf(\"int\")\n",
        "    def late_night(hour):\n",
        "        if ((hour <= 6) and (hour >= 20)):\n",
        "            return int(1)\n",
        "        else:\n",
        "            return int(0)\n",
        "    data = data.withColumn(\"night\", night(\"hour_of_day\", \"day_of_week\"))\n",
        "    data = data.withColumn(\"late_night\", late_night(\"hour_of_day\"))\n",
        "    return data\n",
        "\n",
        "def add_distance_features(data):\n",
        "    @udf(\"float\")\n",
        "    def manhattan(lat1, lon1, lat2, lon2):\n",
        "        return float(np.abs(lat2 - lat1) + np.abs(lon2 - lon1))\n",
        "    \n",
        "    # Location of NYC downtown\n",
        "    ny = (-74.0063889, 40.7141667)\n",
        "    # Location of the three airport in NYC\n",
        "    jfk = (-73.7822222222, 40.6441666667)\n",
        "    ewr = (-74.175, 40.69)\n",
        "    lgr = (-73.87, 40.77)\n",
        "    \n",
        "    # Features about the distance between pickup/dropoff and airport\n",
        "    data = data.withColumn(\"abs_diff_longitude\", abs(col(\"dropoff_longitude\")-col(\"pickup_longitude\"))) \\\n",
        "               .withColumn(\"abs_diff_latitude\", abs(col(\"dropoff_latitude\") - col(\"pickup_latitude\")))\n",
        "    data = data.withColumn(\"manhattan\", col(\"abs_diff_latitude\")+col(\"abs_diff_longitude\"))\n",
        "    data = data.withColumn(\"pickup_distance_jfk\", manhattan(\"pickup_longitude\", \"pickup_latitude\", lit(jfk[0]), lit(jfk[1])))\n",
        "    data = data.withColumn(\"dropoff_distance_jfk\", manhattan(\"dropoff_longitude\", \"dropoff_latitude\", lit(jfk[0]), lit(jfk[1])))\n",
        "    data = data.withColumn(\"pickup_distance_ewr\", manhattan(\"pickup_longitude\", \"pickup_latitude\", lit(ewr[0]), lit(ewr[1])))\n",
        "    data = data.withColumn(\"dropoff_distance_ewr\", manhattan(\"dropoff_longitude\", \"dropoff_latitude\", lit(ewr[0]), lit(ewr[1])))\n",
        "    data = data.withColumn(\"pickup_distance_lgr\", manhattan(\"pickup_longitude\", \"pickup_latitude\", lit(lgr[0]), lit(lgr[1])))\n",
        "    data = data.withColumn(\"dropoff_distance_lgr\", manhattan(\"dropoff_longitude\", \"dropoff_latitude\", lit(lgr[0]), lit(lgr[1])))\n",
        "    data = data.withColumn(\"pickup_distance_downtown\", manhattan(\"pickup_longitude\", \"pickup_latitude\", lit(ny[0]), lit(ny[1])))\n",
        "    data = data.withColumn(\"dropoff_distance_downtown\", manhattan(\"dropoff_longitude\", \"dropoff_latitude\", lit(ny[0]), lit(ny[1])))\n",
        "    \n",
        "    return data\n",
        "\n",
        "def drop_col(data):\n",
        "    data = data.drop(\"pickup_datetime\") \\\n",
        "            .drop(\"pickup_longitude\") \\\n",
        "            .drop(\"pickup_latitude\") \\\n",
        "            .drop(\"dropoff_longitude\") \\\n",
        "            .drop(\"dropoff_latitude\") \\\n",
        "            .drop(\"passenger_count\") \\\n",
        "            .drop(\"key\")\n",
        "    return data\n",
        "\n",
        "def nyc_taxi_preprocess(data):\n",
        "    data = clean_up(data)\n",
        "    data = add_time_features(data)\n",
        "    data = add_distance_features(data)\n",
        "    return drop_col(data)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import ray\n",
        "    import raydp\n",
        "    ray.init()\n",
        "    spark = raydp.init_spark(\"NYCTAXI data processing\",\n",
        "                             num_executors=1,\n",
        "                             executor_cores=1,\n",
        "                             executor_memory='500M',\n",
        "                             configs={\"spark.shuffle.service.enabled\": \"true\"})\n",
        "    data = spark.read.format(\"csv\") \\\n",
        "                     .option(\"header\", \"true\") \\\n",
        "                     .option(\"inferSchema\", \"true\") \\\n",
        "                     .load(NYC_TRAIN_CSV)\n",
        "    # Set spark timezone for processing datetime\n",
        "    spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
        "    # Transform the dataset\n",
        "    data = nyc_taxi_preprocess(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xw9uTBdettD",
        "outputId": "10be47e2-56b5-4d02-a415-050a3f3ed22b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-16 15:39:57,143\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark Run Time =  1.7844066619873047\n",
            "Epoch-0: {'num_samples': 1789, 'epoch': 1.0, 'batch_count': 28.0, 'train_loss': 899.6847279326352, 'last_train_loss': 876.887451171875}\n",
            "Epoch-1: {'num_samples': 1789, 'epoch': 2.0, 'batch_count': 28.0, 'train_loss': 895.1097870299508, 'last_train_loss': 843.1162719726562}\n",
            "Epoch-2: {'num_samples': 1789, 'epoch': 3.0, 'batch_count': 28.0, 'train_loss': 889.6506001369589, 'last_train_loss': 796.5059204101562}\n",
            "Epoch-3: {'num_samples': 1789, 'epoch': 4.0, 'batch_count': 28.0, 'train_loss': 882.1949483019604, 'last_train_loss': 792.7432250976562}\n",
            "Epoch-4: {'num_samples': 1789, 'epoch': 5.0, 'batch_count': 28.0, 'train_loss': 871.5343155410451, 'last_train_loss': 924.8529052734375}\n",
            "Epoch-5: {'num_samples': 1789, 'epoch': 6.0, 'batch_count': 28.0, 'train_loss': 857.8564123214458, 'last_train_loss': 743.6755981445312}\n",
            "Epoch-6: {'num_samples': 1789, 'epoch': 7.0, 'batch_count': 28.0, 'train_loss': 841.239653432216, 'last_train_loss': 687.090576171875}\n",
            "Epoch-7: {'num_samples': 1789, 'epoch': 8.0, 'batch_count': 28.0, 'train_loss': 821.4296932657581, 'last_train_loss': 793.9314575195312}\n",
            "Epoch-8: {'num_samples': 1789, 'epoch': 9.0, 'batch_count': 28.0, 'train_loss': 797.7253485861405, 'last_train_loss': 631.9686889648438}\n",
            "Epoch-9: {'num_samples': 1789, 'epoch': 10.0, 'batch_count': 28.0, 'train_loss': 771.3171903931142, 'last_train_loss': 704.15087890625}\n",
            "Epoch-10: {'num_samples': 1789, 'epoch': 11.0, 'batch_count': 28.0, 'train_loss': 744.0602367181496, 'last_train_loss': 799.6777954101562}\n",
            "Epoch-11: {'num_samples': 1789, 'epoch': 12.0, 'batch_count': 28.0, 'train_loss': 713.9883442298202, 'last_train_loss': 702.2996826171875}\n",
            "Epoch-12: {'num_samples': 1789, 'epoch': 13.0, 'batch_count': 28.0, 'train_loss': 683.0625998260856, 'last_train_loss': 746.5550537109375}\n",
            "Epoch-13: {'num_samples': 1789, 'epoch': 14.0, 'batch_count': 28.0, 'train_loss': 649.4486435729742, 'last_train_loss': 678.8208618164062}\n",
            "Epoch-14: {'num_samples': 1789, 'epoch': 15.0, 'batch_count': 28.0, 'train_loss': 614.5620967039788, 'last_train_loss': 672.8368530273438}\n",
            "Epoch-15: {'num_samples': 1789, 'epoch': 16.0, 'batch_count': 28.0, 'train_loss': 581.3889925057425, 'last_train_loss': 502.9676513671875}\n",
            "Epoch-16: {'num_samples': 1789, 'epoch': 17.0, 'batch_count': 28.0, 'train_loss': 547.2085059535377, 'last_train_loss': 519.3679809570312}\n",
            "Epoch-17: {'num_samples': 1789, 'epoch': 18.0, 'batch_count': 28.0, 'train_loss': 513.7200036430039, 'last_train_loss': 396.6430358886719}\n",
            "Epoch-18: {'num_samples': 1789, 'epoch': 19.0, 'batch_count': 28.0, 'train_loss': 481.13271521562433, 'last_train_loss': 460.3666076660156}\n",
            "Epoch-19: {'num_samples': 1789, 'epoch': 20.0, 'batch_count': 28.0, 'train_loss': 449.12311807699615, 'last_train_loss': 489.09295654296875}\n",
            "Epoch-20: {'num_samples': 1789, 'epoch': 21.0, 'batch_count': 28.0, 'train_loss': 416.784729890946, 'last_train_loss': 324.87664794921875}\n",
            "Epoch-21: {'num_samples': 1789, 'epoch': 22.0, 'batch_count': 28.0, 'train_loss': 386.8427962787728, 'last_train_loss': 419.3415222167969}\n",
            "Epoch-22: {'num_samples': 1789, 'epoch': 23.0, 'batch_count': 28.0, 'train_loss': 361.1222923965411, 'last_train_loss': 375.5104675292969}\n",
            "Epoch-23: {'num_samples': 1789, 'epoch': 24.0, 'batch_count': 28.0, 'train_loss': 334.96833183753415, 'last_train_loss': 179.84864807128906}\n",
            "Epoch-24: {'num_samples': 1789, 'epoch': 25.0, 'batch_count': 28.0, 'train_loss': 312.61032602599107, 'last_train_loss': 241.34042358398438}\n",
            "Epoch-25: {'num_samples': 1789, 'epoch': 26.0, 'batch_count': 28.0, 'train_loss': 293.02264583410664, 'last_train_loss': 360.8038024902344}\n",
            "Epoch-26: {'num_samples': 1789, 'epoch': 27.0, 'batch_count': 28.0, 'train_loss': 270.52381728946864, 'last_train_loss': 260.589599609375}\n",
            "Epoch-27: {'num_samples': 1789, 'epoch': 28.0, 'batch_count': 28.0, 'train_loss': 253.29243551971794, 'last_train_loss': 202.04421997070312}\n",
            "Epoch-28: {'num_samples': 1789, 'epoch': 29.0, 'batch_count': 28.0, 'train_loss': 237.55860750764492, 'last_train_loss': 208.48463439941406}\n",
            "Epoch-29: {'num_samples': 1789, 'epoch': 30.0, 'batch_count': 28.0, 'train_loss': 225.58814819915926, 'last_train_loss': 155.4199676513672}\n",
            "{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 192.77476588244687, 'last_val_loss': 219.5199432373047, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n",
            "Ray Run Time =  21.4855797290802\n"
          ]
        }
      ],
      "source": [
        "import ray\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import raydp\n",
        "from raydp.torch import TorchEstimator\n",
        "from raydp.utils import random_split\n",
        "from time import *\n",
        "\n",
        "from data_process import nyc_taxi_preprocess, NYC_TRAIN_CSV\n",
        "\n",
        "# Firstly, You need to init or connect to a ray cluster. Note that you should set include_java to True.\n",
        "# For more config info in ray, please refer the ray doc. https://docs.ray.io/en/latest/package-ref.html\n",
        "# ray.init(address=\"auto\")\n",
        "ray.init()\n",
        "\n",
        "# After initialize ray cluster, you can use the raydp api to get a spark session\n",
        "app_name = \"NYC Taxi Fare Prediction with RayDP\"\n",
        "num_executors = 1\n",
        "cores_per_executor = 1\n",
        "memory_per_executor = \"500M\"\n",
        "spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)\n",
        "\n",
        "# Then you can code as you are using spark\n",
        "# The dataset can be downloaded from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data\n",
        "# Here we just use a subset of the training data\n",
        "data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
        "        .option(\"inferSchema\", \"true\") \\\n",
        "        .load(NYC_TRAIN_CSV)\n",
        "# Set spark timezone for processing datetime\n",
        "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
        "# Transform the dataset\n",
        "spark_begin_time = time()\n",
        "data = nyc_taxi_preprocess(data)\n",
        "spark_end_time = time()\n",
        "spark_run_time = spark_end_time-spark_begin_time\n",
        "print(\"Spark Run Time = \", spark_run_time)\n",
        "\n",
        "# Split data into train_dataset and test_dataset\n",
        "train_df, test_df = random_split(data, [0.9, 0.1], 0)\n",
        "features = [field.name for field in list(train_df.schema) if field.name != \"fare_amount\"]\n",
        "# Define a neural network model\n",
        "class NYC_Model(nn.Module):\n",
        "    def __init__(self, cols):\n",
        "        super(NYC_Model, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(cols, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 16)\n",
        "        self.fc5 = nn.Linear(16, 1)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.bn4 = nn.BatchNorm1d(16)\n",
        "\n",
        "    def forward(self, *x):\n",
        "        x = torch.cat(x, dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = self.fc5(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "nyc_model = NYC_Model(len(features))\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nyc_model.parameters(), lr=0.001)\n",
        "# Create a distributed estimator based on the raydp api\n",
        "estimator = TorchEstimator(num_workers=1, model=nyc_model, optimizer=optimizer, loss=criterion,\n",
        "                           feature_columns=features, label_column=\"fare_amount\", batch_size=64,\n",
        "                           num_epochs=30)\n",
        "# Train the model\n",
        "ray_begin_time = time()\n",
        "estimator.fit_on_spark(train_df, test_df)\n",
        "ray_end_time = time()\n",
        "ray_run_time = ray_end_time-ray_begin_time\n",
        "print(\"Ray Run Time = \", ray_run_time)\n",
        "# shutdown raydp and ray\n",
        "estimator.shutdown()\n",
        "raydp.stop_spark()\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0x-HHG3DD_a",
        "outputId": "d61d2282-34da-4de5-a4fd-7f43f1cef435"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-16 15:53:19,113\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[1m\u001b[36m(scheduler +13m45s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +13m45s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +14m20s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +14m55s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +15m30s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +16m6s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +16m41s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +17m16s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +17m51s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +18m26s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +19m1s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +19m36s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +20m11s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +20m46s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +21m21s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +21m56s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +22m31s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +23m6s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +23m41s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +24m16s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +24m51s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +25m26s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +26m1s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +26m36s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +27m12s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +27m47s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +28m22s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +28m57s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +29m32s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +30m7s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +30m42s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +31m17s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +31m52s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +32m27s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +33m2s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +33m37s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +34m12s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +34m47s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +35m22s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +35m57s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +36m32s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +37m7s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +37m42s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +38m18s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +38m53s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +39m28s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +40m3s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +40m38s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +41m13s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +41m48s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +42m23s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +42m58s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +43m33s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +44m8s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +44m43s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +45m18s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +45m53s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +46m28s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +47m3s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +47m38s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +48m14s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +48m49s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +49m24s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +49m59s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +50m34s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +51m9s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +51m44s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +52m19s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +52m54s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +53m29s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +54m4s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +54m39s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +55m14s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +55m49s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +56m24s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +56m59s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +57m34s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +58m9s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +58m44s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +59m19s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +59m55s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h30s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h1m5s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h1m40s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h2m15s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h2m50s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h3m25s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h4m0s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h4m35s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h5m10s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h5m45s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h6m20s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h6m55s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h7m30s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h8m5s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h8m40s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h9m15s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h9m50s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 4.0, 'memory': 524288000.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h10m25s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h11m1s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h11m36s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h12m11s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h12m46s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h13m21s)\u001b[0m Error: No available node types can fulfill resource request {'memory': 524288000.0, 'CPU': 4.0}. Add suitable node types to this cluster to resolve this issue.\n"
          ]
        }
      ],
      "source": [
        "import ray\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import raydp\n",
        "from raydp.torch import TorchEstimator\n",
        "from raydp.utils import random_split\n",
        "from time import *\n",
        "\n",
        "from data_process import nyc_taxi_preprocess, NYC_TRAIN_CSV\n",
        "\n",
        "# Firstly, You need to init or connect to a ray cluster. Note that you should set include_java to True.\n",
        "# For more config info in ray, please refer the ray doc. https://docs.ray.io/en/latest/package-ref.html\n",
        "# ray.init(address=\"auto\")\n",
        "ray.init()\n",
        "\n",
        "# After initialize ray cluster, you can use the raydp api to get a spark session\n",
        "app_name = \"NYC Taxi Fare Prediction with RayDP\"\n",
        "num_executors = 1\n",
        "cores_per_executor = 4\n",
        "memory_per_executor = \"500M\"\n",
        "spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)\n",
        "\n",
        "# Then you can code as you are using spark\n",
        "# The dataset can be downloaded from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data\n",
        "# Here we just use a subset of the training data\n",
        "data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
        "        .option(\"inferSchema\", \"true\") \\\n",
        "        .load(NYC_TRAIN_CSV)\n",
        "# Set spark timezone for processing datetime\n",
        "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
        "# Transform the dataset\n",
        "spark_begin_time = time()\n",
        "data = nyc_taxi_preprocess(data)\n",
        "spark_end_time = time()\n",
        "spark_run_time = spark_end_time-spark_begin_time\n",
        "print(\"Spark Run Time = \", spark_run_time)\n",
        "\n",
        "# Split data into train_dataset and test_dataset\n",
        "train_df, test_df = random_split(data, [0.9, 0.1], 0)\n",
        "features = [field.name for field in list(train_df.schema) if field.name != \"fare_amount\"]\n",
        "# Define a neural network model\n",
        "class NYC_Model(nn.Module):\n",
        "    def __init__(self, cols):\n",
        "        super(NYC_Model, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(cols, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 16)\n",
        "        self.fc5 = nn.Linear(16, 1)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.bn4 = nn.BatchNorm1d(16)\n",
        "\n",
        "    def forward(self, *x):\n",
        "        x = torch.cat(x, dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = self.fc5(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "nyc_model = NYC_Model(len(features))\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nyc_model.parameters(), lr=0.001)\n",
        "# Create a distributed estimator based on the raydp api\n",
        "estimator = TorchEstimator(num_workers=1, model=nyc_model, optimizer=optimizer, loss=criterion,\n",
        "                           feature_columns=features, label_column=\"fare_amount\", batch_size=64,\n",
        "                           num_epochs=30)\n",
        "# Train the model\n",
        "ray_begin_time = time()\n",
        "estimator.fit_on_spark(train_df, test_df)\n",
        "ray_end_time = time()\n",
        "ray_run_time = ray_end_time-ray_begin_time\n",
        "print(\"Ray Run Time = \", ray_run_time)\n",
        "# shutdown raydp and ray\n",
        "estimator.shutdown()\n",
        "raydp.stop_spark()\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "FElohaeXDHNx",
        "outputId": "fde75996-26ca-4962-8b7c-fe9d1f9112d3"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-24a18e5fc123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import ray\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import raydp\n",
        "from raydp.torch import TorchEstimator\n",
        "from raydp.utils import random_split\n",
        "from time import *\n",
        "\n",
        "from data_process import nyc_taxi_preprocess, NYC_TRAIN_CSV\n",
        "\n",
        "# Firstly, You need to init or connect to a ray cluster. Note that you should set include_java to True.\n",
        "# For more config info in ray, please refer the ray doc. https://docs.ray.io/en/latest/package-ref.html\n",
        "# ray.init(address=\"auto\")\n",
        "ray.init()\n",
        "\n",
        "# After initialize ray cluster, you can use the raydp api to get a spark session\n",
        "app_name = \"NYC Taxi Fare Prediction with RayDP\"\n",
        "num_executors = 1\n",
        "cores_per_executor = 4\n",
        "memory_per_executor = \"500M\"\n",
        "spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)\n",
        "\n",
        "# Then you can code as you are using spark\n",
        "# The dataset can be downloaded from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data\n",
        "# Here we just use a subset of the training data\n",
        "data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
        "        .option(\"inferSchema\", \"true\") \\\n",
        "        .load(NYC_TRAIN_CSV)\n",
        "# Set spark timezone for processing datetime\n",
        "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
        "# Transform the dataset\n",
        "spark_begin_time = time()\n",
        "data = nyc_taxi_preprocess(data)\n",
        "spark_end_time = time()\n",
        "spark_run_time = spark_end_time-spark_begin_time\n",
        "print(\"Spark Run Time = \", spark_run_time)\n",
        "\n",
        "# Split data into train_dataset and test_dataset\n",
        "train_df, test_df = random_split(data, [0.9, 0.1], 0)\n",
        "features = [field.name for field in list(train_df.schema) if field.name != \"fare_amount\"]\n",
        "# Define a neural network model\n",
        "class NYC_Model(nn.Module):\n",
        "    def __init__(self, cols):\n",
        "        super(NYC_Model, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(cols, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 16)\n",
        "        self.fc5 = nn.Linear(16, 1)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.bn4 = nn.BatchNorm1d(16)\n",
        "\n",
        "    def forward(self, *x):\n",
        "        x = torch.cat(x, dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = self.fc5(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "nyc_model = NYC_Model(len(features))\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nyc_model.parameters(), lr=0.001)\n",
        "# Create a distributed estimator based on the raydp api\n",
        "estimator = TorchEstimator(num_workers=1, model=nyc_model, optimizer=optimizer, loss=criterion,\n",
        "                           feature_columns=features, label_column=\"fare_amount\", batch_size=64,\n",
        "                           num_epochs=30)\n",
        "# Train the model\n",
        "ray_begin_time = time()\n",
        "estimator.fit_on_spark(train_df, test_df)\n",
        "ray_end_time = time()\n",
        "ray_run_time = ray_end_time-ray_begin_time\n",
        "print(\"Ray Run Time = \", ray_run_time)\n",
        "# shutdown raydp and ray\n",
        "estimator.shutdown()\n",
        "raydp.stop_spark()\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8-B--bCDJnK"
      },
      "outputs": [],
      "source": [
        "import ray\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import raydp\n",
        "from raydp.torch import TorchEstimator\n",
        "from raydp.utils import random_split\n",
        "from time import *\n",
        "\n",
        "from data_process import nyc_taxi_preprocess, NYC_TRAIN_CSV\n",
        "\n",
        "# Firstly, You need to init or connect to a ray cluster. Note that you should set include_java to True.\n",
        "# For more config info in ray, please refer the ray doc. https://docs.ray.io/en/latest/package-ref.html\n",
        "# ray.init(address=\"auto\")\n",
        "ray.init()\n",
        "\n",
        "# After initialize ray cluster, you can use the raydp api to get a spark session\n",
        "app_name = \"NYC Taxi Fare Prediction with RayDP\"\n",
        "num_executors = 1\n",
        "cores_per_executor = 8\n",
        "memory_per_executor = \"500M\"\n",
        "spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)\n",
        "\n",
        "# Then you can code as you are using spark\n",
        "# The dataset can be downloaded from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data\n",
        "# Here we just use a subset of the training data\n",
        "data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
        "        .option(\"inferSchema\", \"true\") \\\n",
        "        .load(NYC_TRAIN_CSV)\n",
        "# Set spark timezone for processing datetime\n",
        "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
        "# Transform the dataset\n",
        "spark_begin_time = time()\n",
        "data = nyc_taxi_preprocess(data)\n",
        "spark_end_time = time()\n",
        "spark_run_time = spark_end_time-spark_begin_time\n",
        "print(\"Spark Run Time = \", spark_run_time)\n",
        "\n",
        "# Split data into train_dataset and test_dataset\n",
        "train_df, test_df = random_split(data, [0.9, 0.1], 0)\n",
        "features = [field.name for field in list(train_df.schema) if field.name != \"fare_amount\"]\n",
        "# Define a neural network model\n",
        "class NYC_Model(nn.Module):\n",
        "    def __init__(self, cols):\n",
        "        super(NYC_Model, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(cols, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 16)\n",
        "        self.fc5 = nn.Linear(16, 1)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.bn4 = nn.BatchNorm1d(16)\n",
        "\n",
        "    def forward(self, *x):\n",
        "        x = torch.cat(x, dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = self.fc5(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "nyc_model = NYC_Model(len(features))\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nyc_model.parameters(), lr=0.001)\n",
        "# Create a distributed estimator based on the raydp api\n",
        "estimator = TorchEstimator(num_workers=1, model=nyc_model, optimizer=optimizer, loss=criterion,\n",
        "                           feature_columns=features, label_column=\"fare_amount\", batch_size=64,\n",
        "                           num_epochs=30)\n",
        "# Train the model\n",
        "ray_begin_time = time()\n",
        "estimator.fit_on_spark(train_df, test_df)\n",
        "ray_end_time = time()\n",
        "ray_run_time = ray_end_time-ray_begin_time\n",
        "print(\"Ray Run Time = \", ray_run_time)\n",
        "# shutdown raydp and ray\n",
        "estimator.shutdown()\n",
        "raydp.stop_spark()\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_4no1LgDNS2",
        "outputId": "3a3bb6dd-efbd-45cd-f809-2a14acb31aad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-16 13:25:18,618\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark Run Time =  1.1537659168243408\n",
            "\u001b[2m\u001b[1m\u001b[36m(scheduler +58s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +58s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-16 13:26:19,690\tWARNING worker.py:1245 -- The actor or task with ID ffffffffffffffff0ea38786fea00a4b7905828a01000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
            "Required resources for this actor or task: {GPU: 1.000000}, {CPU: 1.000000}\n",
            "Available resources on this node: {0.000000/2.000000 CPU, 320050000.000000 GiB/371250000.000000 GiB memory, 1.000000/1.000000 GPU, 185625000.000000 GiB/185625000.000000 GiB object_store_memory, 1.000000/1.000000 node:172.28.0.2, 1.000000/1.000000 accelerator_type:T4}\n",
            " In total there are 0 pending tasks and 1 pending actors on this node.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1m33s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +2m8s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +2m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +3m18s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +3m53s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +4m28s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +5m3s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +5m38s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        }
      ],
      "source": [
        "import ray\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import raydp\n",
        "from raydp.torch import TorchEstimator\n",
        "from raydp.utils import random_split\n",
        "from time import *\n",
        "\n",
        "from data_process import nyc_taxi_preprocess, NYC_TRAIN_CSV\n",
        "\n",
        "# Firstly, You need to init or connect to a ray cluster. Note that you should set include_java to True.\n",
        "# For more config info in ray, please refer the ray doc. https://docs.ray.io/en/latest/package-ref.html\n",
        "# ray.init(address=\"auto\")\n",
        "# raydp.stop_spark()\n",
        "# ray.shutdown()\n",
        "ray.init()\n",
        "\n",
        "# After initialize ray cluster, you can use the raydp api to get a spark session\n",
        "app_name = \"NYC Taxi Fare Prediction with RayDP\"\n",
        "num_executors = 2\n",
        "cores_per_executor = 1\n",
        "memory_per_executor = \"500M\"\n",
        "spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)\n",
        "\n",
        "# Then you can code as you are using spark\n",
        "# The dataset can be downloaded from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data\n",
        "# Here we just use a subset of the training data\n",
        "data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
        "        .option(\"inferSchema\", \"true\") \\\n",
        "        .load(NYC_TRAIN_CSV)\n",
        "# Set spark timezone for processing datetime\n",
        "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
        "# Transform the dataset\n",
        "spark_begin_time = time()\n",
        "data = nyc_taxi_preprocess(data)\n",
        "spark_end_time = time()\n",
        "spark_run_time = spark_end_time-spark_begin_time\n",
        "print(\"Spark Run Time = \", spark_run_time)\n",
        "\n",
        "# Split data into train_dataset and test_dataset\n",
        "train_df, test_df = random_split(data, [0.9, 0.1], 0)\n",
        "features = [field.name for field in list(train_df.schema) if field.name != \"fare_amount\"]\n",
        "# Define a neural network model\n",
        "class NYC_Model(nn.Module):\n",
        "    def __init__(self, cols):\n",
        "        super(NYC_Model, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(cols, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 16)\n",
        "        self.fc5 = nn.Linear(16, 1)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.bn4 = nn.BatchNorm1d(16)\n",
        "\n",
        "    def forward(self, *x):\n",
        "        x = torch.cat(x, dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = self.fc5(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "nyc_model = NYC_Model(len(features))\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nyc_model.parameters(), lr=0.001)\n",
        "# Create a distributed estimator based on the raydp api\n",
        "estimator = TorchEstimator(num_workers=1, model=nyc_model, optimizer=optimizer, loss=criterion,\n",
        "                           feature_columns=features, label_column=\"fare_amount\", batch_size=64,\n",
        "                           num_epochs=30)\n",
        "# Train the model\n",
        "ray_begin_time = time()\n",
        "estimator.fit_on_spark(train_df, test_df)\n",
        "ray_end_time = time()\n",
        "ray_run_time = ray_end_time-ray_begin_time\n",
        "print(\"Ray Run Time = \", ray_run_time)\n",
        "# shutdown raydp and ray\n",
        "estimator.shutdown()\n",
        "raydp.stop_spark()\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA3S9mPODO7Z"
      },
      "outputs": [],
      "source": [
        "import ray\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import raydp\n",
        "from raydp.torch import TorchEstimator\n",
        "from raydp.utils import random_split\n",
        "from time import *\n",
        "\n",
        "from data_process import nyc_taxi_preprocess, NYC_TRAIN_CSV\n",
        "\n",
        "# Firstly, You need to init or connect to a ray cluster. Note that you should set include_java to True.\n",
        "# For more config info in ray, please refer the ray doc. https://docs.ray.io/en/latest/package-ref.html\n",
        "# ray.init(address=\"auto\")\n",
        "ray.init()\n",
        "\n",
        "# After initialize ray cluster, you can use the raydp api to get a spark session\n",
        "app_name = \"NYC Taxi Fare Prediction with RayDP\"\n",
        "num_executors = 4\n",
        "cores_per_executor = 1\n",
        "memory_per_executor = \"500M\"\n",
        "spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)\n",
        "\n",
        "# Then you can code as you are using spark\n",
        "# The dataset can be downloaded from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data\n",
        "# Here we just use a subset of the training data\n",
        "data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
        "        .option(\"inferSchema\", \"true\") \\\n",
        "        .load(NYC_TRAIN_CSV)\n",
        "# Set spark timezone for processing datetime\n",
        "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
        "# Transform the dataset\n",
        "spark_begin_time = time()\n",
        "data = nyc_taxi_preprocess(data)\n",
        "spark_end_time = time()\n",
        "spark_run_time = spark_end_time-spark_begin_time\n",
        "print(\"Spark Run Time = \", spark_run_time)\n",
        "\n",
        "# Split data into train_dataset and test_dataset\n",
        "train_df, test_df = random_split(data, [0.9, 0.1], 0)\n",
        "features = [field.name for field in list(train_df.schema) if field.name != \"fare_amount\"]\n",
        "# Define a neural network model\n",
        "class NYC_Model(nn.Module):\n",
        "    def __init__(self, cols):\n",
        "        super(NYC_Model, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(cols, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 16)\n",
        "        self.fc5 = nn.Linear(16, 1)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.bn4 = nn.BatchNorm1d(16)\n",
        "\n",
        "    def forward(self, *x):\n",
        "        x = torch.cat(x, dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = self.fc5(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "nyc_model = NYC_Model(len(features))\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nyc_model.parameters(), lr=0.001)\n",
        "# Create a distributed estimator based on the raydp api\n",
        "estimator = TorchEstimator(num_workers=1, model=nyc_model, optimizer=optimizer, loss=criterion,\n",
        "                           feature_columns=features, label_column=\"fare_amount\", batch_size=64,\n",
        "                           num_epochs=30)\n",
        "# Train the model\n",
        "ray_begin_time = time()\n",
        "estimator.fit_on_spark(train_df, test_df)\n",
        "ray_end_time = time()\n",
        "ray_run_time = ray_end_time-ray_begin_time\n",
        "print(\"Ray Run Time = \", ray_run_time)\n",
        "# shutdown raydp and ray\n",
        "estimator.shutdown()\n",
        "raydp.stop_spark()\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0oGrCpKDXfC"
      },
      "outputs": [],
      "source": [
        "!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NYU taxi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}